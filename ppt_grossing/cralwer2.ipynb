{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 篇文章完成!\n",
      "第 2 篇文章完成!\n",
      "第 3 篇文章完成!\n",
      "第 4 篇文章完成!\n",
      "第 5 篇文章完成!\n",
      "第 6 篇文章完成!\n",
      "第 7 篇文章完成!\n",
      "第 8 篇文章完成!\n",
      "第 9 篇文章完成!\n",
      "第 10 篇文章完成!\n",
      "第 11 篇文章完成!\n",
      "第 12 篇文章完成!\n",
      "第 13 篇文章完成!\n",
      "第 14 篇文章完成!\n",
      "第 15 篇文章完成!\n",
      "第 16 篇文章完成!\n",
      "第 17 篇文章完成!\n",
      "第 18 篇文章完成!\n",
      "第 19 篇文章完成!\n",
      "第 20 篇文章完成!\n",
      "第 21 篇文章完成!\n",
      "第 22 篇文章完成!\n",
      "第 23 篇文章完成!\n",
      "第 24 篇文章完成!\n",
      "第 25 篇文章完成!\n",
      "第 26 篇文章完成!\n",
      "第 27 篇文章完成!\n",
      "第 28 篇文章完成!\n",
      "第 29 篇文章完成!\n",
      "第 30 篇文章完成!\n",
      "第 31 篇文章完成!\n",
      "第 32 篇文章完成!\n",
      "第 33 篇文章完成!\n",
      "第 34 篇文章完成!\n",
      "第 35 篇文章完成!\n"
     ]
    }
   ],
   "source": [
    "# PTT八卦版爬蟲\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# 基本參數\n",
    "url = \"https://www.ptt.cc/bbs/Gossiping/index.html\"\n",
    "payload = {\n",
    "    'from': '/bbs/Gossiping/index.html',\n",
    "    'yes': 'yes'\n",
    "}\n",
    "data = []   # 全部文章的資料\n",
    "num = 0\n",
    "\n",
    "# 用session紀錄此次使用的cookie\n",
    "rs = requests.session()\n",
    "response = rs.post(\"https://www.ptt.cc/ask/over18\", data=payload)\n",
    "\n",
    "# 爬取兩頁\n",
    "for i in range(2):\n",
    "    # get取得頁面的HTML\n",
    "    # print(url)\n",
    "    response = rs.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    # print(soup.prettify())\n",
    "\n",
    "    # 找出每篇文章的連結\n",
    "    links = soup.find_all(\"div\", class_=\"title\")\n",
    "    for link in links:\n",
    "        # 如果文章已被刪除，連結為None\n",
    "        if link.a != None:\n",
    "\n",
    "            article_data = {}   # 單篇文章的資料\n",
    "            page_url = \"https://www.ptt.cc/\"+link.a[\"href\"]\n",
    "\n",
    "            # 進入文章頁面\n",
    "            response = rs.get(page_url)\n",
    "            result = BeautifulSoup(response.text, \"html.parser\")\n",
    "            # print(soup.prettify())\n",
    "\n",
    "            # 找出作者、標題、時間、留言\n",
    "            main_content = result.find(\"div\", id=\"main-content\")\n",
    "            article_info = main_content.find_all(\n",
    "                \"span\", class_=\"article-meta-value\")\n",
    "\n",
    "            if len(article_info) != 0:\n",
    "                author = article_info[0].string  # 作者\n",
    "                title = article_info[2].string  # 標題\n",
    "                time = article_info[3].string   # 時間\n",
    "            else:\n",
    "                author = \"無\"  # 作者\n",
    "                title = \"無\"  # 標題\n",
    "                time = \"無\"   # 時間\n",
    "\n",
    "            # print(author)\n",
    "            # print(title)\n",
    "            # print(time)\n",
    "\n",
    "            article_data[\"author\"] = author\n",
    "            article_data[\"title\"] = title\n",
    "            article_data[\"time\"] = time\n",
    "\n",
    "            # 將整段文字內容抓出來\n",
    "            all_text = main_content.text\n",
    "            # 以--切割，抓最後一個--前的所有內容\n",
    "            pre_texts = all_text.split(\"--\")[:-1]\n",
    "            # 將前面的所有內容合併成一個\n",
    "            one_text = \"--\".join(pre_texts)\n",
    "            # 以\\n切割，第一行標題不要\n",
    "            texts = one_text.split(\"\\n\")[1:]\n",
    "            # 將每一行合併\n",
    "            content = \"\\n\".join(texts)\n",
    "\n",
    "            # print(content)\n",
    "            article_data[\"content\"] = content\n",
    "\n",
    "            # 一種留言一個列表\n",
    "            comment_dic = {}\n",
    "            push_dic = []\n",
    "            arrow_dic = []\n",
    "            shu_dic = []\n",
    "\n",
    "            # 抓出所有留言\n",
    "            comments = main_content.find_all(\"div\", class_=\"push\")\n",
    "            for comment in comments:\n",
    "                push_tag = comment.find(\n",
    "                    \"span\", class_=\"push-tag\").string   # 分類標籤\n",
    "                push_userid = comment.find(\n",
    "                    \"span\", class_=\"push-userid\").string  # 使用者ID\n",
    "                push_content = comment.find(\n",
    "                    \"span\", class_=\"push-content\").string   # 留言內容\n",
    "                push_time = comment.find(\n",
    "                    \"span\", class_=\"push-ipdatetime\").string   # 留言時間\n",
    "\n",
    "                # print(push_tag, push_userid, push_content, push_time)\n",
    "\n",
    "                dict1 = {\"push_userid\": push_userid,\n",
    "                         \"push_content\": push_content, \"push_time\": push_time}\n",
    "                if push_tag == \"推 \":\n",
    "                    push_dic.append(dict1)\n",
    "                if push_tag == \"→ \":\n",
    "                    arrow_dic.append(dict1)\n",
    "                if push_tag == \"噓 \":\n",
    "                    shu_dic.append(dict1)\n",
    "\n",
    "            # print(push_dic)\n",
    "            # print(arrow_dic)\n",
    "            # print(shu_dic)\n",
    "            # print(\"--------\")\n",
    "\n",
    "            comment_dic[\"推\"] = push_dic\n",
    "            comment_dic[\"→\"] = arrow_dic\n",
    "            comment_dic[\"噓\"] = shu_dic\n",
    "            article_data[\"comment\"] = comment_dic\n",
    "\n",
    "            # print(article_data)\n",
    "            data.append(article_data)\n",
    "            num += 1\n",
    "            print(\"第 \"+str(num)+\" 篇文章完成!\")\n",
    "\n",
    "    # 找到上頁的網址，並更新url\n",
    "    url = \"https://www.ptt.cc/\"+soup.find(\"a\", string=\"‹ 上頁\")[\"href\"]\n",
    "\n",
    "    # print(data)\n",
    "# 輸出JSON檔案\n",
    "with open('data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
